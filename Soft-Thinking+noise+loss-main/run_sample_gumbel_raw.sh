
python run_sglang_softthinking.py \
    --dataset "aime2024" \
    --model_name ********************************/meta-llama/DeepSeek-R1-Distill-Qwen-1.5B \
    --max_topk 30 \
    --max_generated_tokens 32768 \
    --temperature 0.6 \
    --top_p 0.95 \
    --top_k 30 \
    --min_p 0.0 \
    --after_thinking_temperature 0.6 \
    --after_thinking_top_p 0.95 \
    --after_thinking_top_k 30 \
    --after_thinking_min_p 0.0 \
    --mem_fraction_static 0.8 \
    --start_idx 0 \
    --end_idx 1000 \
    --num_gpus 1 \
    --num_samples 32 \
    --enable_soft_thinking \
    --add_noise_gumbel_softmax \
    --gumbel_softmax_temperature 0.5 \
    --noise_factor 1 

python run_sglang_softthinking.py \
    --dataset "aime2025" \
    --model_name ********************************/meta-llama/DeepSeek-R1-Distill-Qwen-1.5B \
    --max_topk 30 \
    --max_generated_tokens 32768 \
    --temperature 0.6 \
    --top_p 0.95 \
    --top_k 30 \
    --min_p 0.0 \
    --after_thinking_temperature 0.6 \
    --after_thinking_top_p 0.95 \
    --after_thinking_top_k 30 \
    --after_thinking_min_p 0.0 \
    --mem_fraction_static 0.8 \
    --start_idx 0 \
    --end_idx 1000 \
    --num_gpus 1 \
    --num_samples 32 \
    --enable_soft_thinking \
    --add_noise_gumbel_softmax \
    --gumbel_softmax_temperature 0.5 \
    --noise_factor 1 

python run_sglang_softthinking.py \
    --dataset "amc23" \
    --model_name ********************************/meta-llama/DeepSeek-R1-Distill-Qwen-1.5B \
    --max_topk 30 \
    --max_generated_tokens 32768 \
    --temperature 0.6 \
    --top_p 0.95 \
    --top_k 30 \
    --min_p 0.0 \
    --after_thinking_temperature 0.6 \
    --after_thinking_top_p 0.95 \
    --after_thinking_top_k 30 \
    --after_thinking_min_p 0.0 \
    --mem_fraction_static 0.8 \
    --start_idx 0 \
    --end_idx 1000 \
    --num_gpus 1 \
    --num_samples 32 \
    --enable_soft_thinking \
    --add_noise_gumbel_softmax \
    --gumbel_softmax_temperature 0.5 \
    --noise_factor 1 

python run_sglang_softthinking.py \
    --dataset "math500" \
    --model_name ********************************/meta-llama/DeepSeek-R1-Distill-Qwen-1.5B \
    --max_topk 30 \
    --max_generated_tokens 32768 \
    --temperature 0.6 \
    --top_p 0.95 \
    --top_k 30 \
    --min_p 0.0 \
    --after_thinking_temperature 0.6 \
    --after_thinking_top_p 0.95 \
    --after_thinking_top_k 30 \
    --after_thinking_min_p 0.0 \
    --mem_fraction_static 0.8 \
    --start_idx 0 \
    --end_idx 1000 \
    --num_gpus 1 \
    --num_samples 32 \
    --enable_soft_thinking \
    --add_noise_gumbel_softmax \
    --gumbel_softmax_temperature 0.5 \
    --noise_factor 1 

python run_sglang_softthinking.py \
    --dataset "gsm8k" \
    --model_name ********************************/meta-llama/DeepSeek-R1-Distill-Qwen-1.5B \
    --max_topk 30 \
    --max_generated_tokens 32768 \
    --temperature 0.6 \
    --top_p 0.95 \
    --top_k 30 \
    --min_p 0.0 \
    --after_thinking_temperature 0.6 \
    --after_thinking_top_p 0.95 \
    --after_thinking_top_k 30 \
    --after_thinking_min_p 0.0 \
    --mem_fraction_static 0.8 \
    --start_idx 0 \
    --end_idx 1500 \
    --num_gpus 1 \
    --num_samples 32 \
    --enable_soft_thinking \
    --add_noise_gumbel_softmax \
    --gumbel_softmax_temperature 0.5 \
    --noise_factor 1 

python run_sglang_softthinking.py \
    --dataset "gpqa_diamond" \
    --model_name ********************************/meta-llama/DeepSeek-R1-Distill-Qwen-1.5B \
    --max_topk 30 \
    --max_generated_tokens 32768 \
    --temperature 0.6 \
    --top_p 0.95 \
    --top_k 30 \
    --min_p 0.0 \
    --after_thinking_temperature 0.6 \
    --after_thinking_top_p 0.95 \
    --after_thinking_top_k 30 \
    --after_thinking_min_p 0.0 \
    --mem_fraction_static 0.8 \
    --start_idx 0 \
    --end_idx 1000 \
    --num_gpus 1 \
    --num_samples 32 \
    --enable_soft_thinking \
    --add_noise_gumbel_softmax \
    --gumbel_softmax_temperature 0.5 \
    --noise_factor 1 


python run_sglang_softthinking.py \
    --dataset "humaneval" \
    --model_name ********************************/meta-llama/DeepSeek-R1-Distill-Qwen-1.5B \
    --max_topk 30 \
    --max_generated_tokens 32768 \
    --temperature 0.6 \
    --top_p 0.95 \
    --top_k 30 \
    --min_p 0.0 \
    --after_thinking_temperature 0.6 \
    --after_thinking_top_p 0.95 \
    --after_thinking_top_k 30 \
    --after_thinking_min_p 0.0 \
    --mem_fraction_static 0.8 \
    --start_idx 0 \
    --end_idx 1000 \
    --num_gpus 1 \
    --num_samples 32 \
    --enable_soft_thinking \
    --add_noise_gumbel_softmax \
    --gumbel_softmax_temperature 0.5 \
    --noise_factor 1 

python run_sglang_softthinking.py \
    --dataset "mbpp" \
    --model_name ********************************/meta-llama/DeepSeek-R1-Distill-Qwen-1.5B \
    --max_topk 30 \
    --max_generated_tokens 32768 \
    --temperature 0.6 \
    --top_p 0.95 \
    --top_k 30 \
    --min_p 0.0 \
    --after_thinking_temperature 0.6 \
    --after_thinking_top_p 0.95 \
    --after_thinking_top_k 30 \
    --after_thinking_min_p 0.0 \
    --mem_fraction_static 0.8 \
    --start_idx 0 \
    --end_idx 1000 \
    --num_gpus 1 \
    --num_samples 32 \
    --enable_soft_thinking \
    --add_noise_gumbel_softmax \
    --gumbel_softmax_temperature 0.5 \
    --noise_factor 1 


python run_sglang_softthinking.py \
    --dataset "humaneval" \
    --model_name ********************************/meta-llama/DeepSeek-R1-Distill-Qwen-1.5B \
    --max_topk 30 \
    --max_generated_tokens 32768 \
    --temperature 0.6 \
    --top_p 0.95 \
    --top_k 30 \
    --min_p 0.0 \
    --after_thinking_temperature 0.6 \
    --after_thinking_top_p 0.95 \
    --after_thinking_top_k 30 \
    --after_thinking_min_p 0.0 \
    --mem_fraction_static 0.8 \
    --start_idx 0 \
    --end_idx 1000 \
    --num_gpus 1 \
    --num_samples 32 \
    --enable_soft_thinking \
    --add_noise_gumbel_softmax \
    --gumbel_softmax_temperature 0.5 \
    --reeval \
    --noise_factor 1 

python run_sglang_softthinking.py \
    --dataset "mbpp" \
    --model_name ********************************/meta-llama/DeepSeek-R1-Distill-Qwen-1.5B \
    --max_topk 30 \
    --max_generated_tokens 32768 \
    --temperature 0.6 \
    --top_p 0.95 \
    --top_k 30 \
    --min_p 0.0 \
    --after_thinking_temperature 0.6 \
    --after_thinking_top_p 0.95 \
    --after_thinking_top_k 30 \
    --after_thinking_min_p 0.0 \
    --mem_fraction_static 0.8 \
    --start_idx 0 \
    --end_idx 1000 \
    --num_gpus 1 \
    --num_samples 32 \
    --enable_soft_thinking \
    --add_noise_gumbel_softmax \
    --gumbel_softmax_temperature 0.5 \
    --reeval \
    --noise_factor 1 



EOF